Search.setIndex({docnames:["KoshurRecognition","index","torch_implem","torch_implem.utils","torch_implem.utils.data","torch_implem.utils.models"],envversion:{"sphinx.domains.c":1,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":1,"sphinx.domains.javascript":1,"sphinx.domains.math":2,"sphinx.domains.python":1,"sphinx.domains.rst":1,"sphinx.domains.std":1,sphinx:56},filenames:["KoshurRecognition.rst","index.rst","torch_implem.rst","torch_implem.utils.rst","torch_implem.utils.data.rst","torch_implem.utils.models.rst"],objects:{"KoshurRecognition.torch_implem":{ocr:[2,0,0,"-"],segmenter:[2,0,0,"-"]},"KoshurRecognition.torch_implem.ocr":{WordDetector:[2,1,1,""]},"KoshurRecognition.torch_implem.segmenter":{BaselineDetector:[2,1,1,""]},"KoshurRecognition.torch_implem.segmenter.BaselineDetector":{load_model:[2,2,1,""],save_checkpoint:[2,2,1,""]},"KoshurRecognition.torch_implem.utils.data":{augmentation:[4,0,0,"-"],dataloader:[4,0,0,"-"]},"KoshurRecognition.torch_implem.utils.data.dataloader":{OCRDataLoader:[4,1,1,""],SegmentationDataLoader:[4,1,1,""]},"KoshurRecognition.torch_implem.utils.models":{ocr_model:[5,0,0,"-"],segmentation_model:[5,0,0,"-"]},"KoshurRecognition.torch_implem.utils.models.segmentation_model":{Identity:[5,1,1,""]}},objnames:{"0":["py","module","Python module"],"1":["py","class","Python class"],"2":["py","method","Python method"]},objtypes:{"0":"py:module","1":"py:class","2":"py:method"},terms:{"class":[2,4,5],"default":2,"function":2,"int":2,appli:2,arg:2,baselinedetector:2,batch:2,batch_siz:2,bool:2,both:2,checkpoint:2,contain:2,content:1,data:[0,1,2,3],dataload:[2,4],dataset:2,decoder_hidden:2,decoder_nlay:2,decoder_output:2,decript:2,delet:5,devic:2,directori:2,dropout:2,encoder_hidden:2,encoder_input:2,encoder_nlay:2,file:2,have:2,ident:5,image_dir:[2,4],index:1,input_dir:4,instead:2,just:5,koshurrecognit:[2,4,5],label:2,label_dir:4,label_path:2,labels_path:4,later:2,layer:5,load_model:2,loader:2,main:2,max_length:2,model:[0,1,2,3],modul:1,name:2,none:[2,4],object:2,ocr:[2,4],ocrdataload:4,onli:2,option:2,origin:2,page:1,pass:2,path:2,pretrain:5,pth:2,root:2,save_checkpoint:2,save_model:2,search:1,segment:2,segmentation_model:5,segmentationdataload:4,set:2,should:2,shuffl:2,size:2,some:5,str:2,subdirectori:2,thi:2,torch_implem:[0,1],torchvis:2,train:2,train_dir:2,transform:[2,4],two:2,used:2,util:[0,1,2],val:2,val_dir:2,valid:2,whether:2,worddetector:2,work:2,you:2},titles:["KoshurRecognition","Welcome to KoshurRecognition\u2019s documentation!","torch_implem","torch_implem.utils","torch_implem.utils.data","torch_implem.utils.models"],titleterms:{data:4,document:1,indic:1,koshurrecognit:[0,1],model:5,tabl:1,torch_implem:[2,3,4,5],util:[3,4,5],welcom:1}})